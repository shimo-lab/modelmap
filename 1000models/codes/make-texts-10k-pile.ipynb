{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_corpus(dataset, max_bytes=1024, min_bytes=256):\n",
    "    text_data = dataset['text']\n",
    "    meta_data = dataset['meta']\n",
    "    for pile_idx, (text, meta) in tqdm(enumerate(zip(text_data, meta_data))):\n",
    "        chunk_list = split_utf8(text, max_bytes)\n",
    "        for chunk_idx, chunk in enumerate(chunk_list):\n",
    "            if is_enough_length(chunk, min_bytes):\n",
    "                yield {\n",
    "                    'pile_idx': pile_idx,\n",
    "                    'chunk_idx': chunk_idx,\n",
    "                    'text': chunk,\n",
    "                    'pile_set_name': meta['pile_set_name']\n",
    "                }\n",
    "\n",
    "def split_utf8_rec(text, max_bytes=1024):\n",
    "    if not text:\n",
    "        return []\n",
    "    encoded = text.encode('utf-8')\n",
    "    if len(encoded) <= max_bytes:\n",
    "        return [text]\n",
    "    split_pos = max_bytes\n",
    "    while encoded[split_pos] & 0xC0 == 0x80:\n",
    "        split_pos -= 1\n",
    "    first_chunk = encoded[:split_pos].decode('utf-8')\n",
    "    rest = encoded[split_pos:].decode('utf-8')\n",
    "    return [first_chunk] + split_utf8_rec(rest, max_bytes)\n",
    "\n",
    "def split_utf8(text, max_bytes=1024):\n",
    "    chunks = []\n",
    "    current_text = text\n",
    "    while len(current_text.encode('utf-8')) > max_bytes:\n",
    "        encoded = current_text.encode('utf-8')\n",
    "        split_pos = max_bytes\n",
    "        while encoded[split_pos] & 0xC0 == 0x80:\n",
    "            split_pos -= 1\n",
    "        decoded_chunk = encoded[:split_pos].decode('utf-8')\n",
    "        chunks.append(decoded_chunk)\n",
    "        current_text = encoded[split_pos:].decode('utf-8')\n",
    "    if current_text:\n",
    "        chunks.append(current_text)\n",
    "    return chunks\n",
    "\n",
    "def is_enough_length(text, min_bytes=256):\n",
    "    return len(text.encode('utf-8')) > min_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "# dataset = load_dataset(\"monology/pile-uncopyrighted\")\n",
    "# dataset = dataset['train']\n",
    "corpus_1M = dataset[:1_000_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000000it [04:41, 3557.06it/s]\n"
     ]
    }
   ],
   "source": [
    "chunked = list(chunk_corpus(corpus_1M, max_bytes=1024, min_bytes=256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5703791"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1 = random.sample(chunked, 40_000)\n",
    "ds1 = ds1[:10_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(ds1): 10000\n",
      "ds1[0]: {'pile_idx': 940294, 'chunk_idx': 237, 'text': \"s of\\nour wonderful Abbey Church.\\n\\n[Illustration: CHEAPSIDE CROSS.]\\n\\nCheapside Cross was 're-edified' in 1441, and afterwards newly gilt and\\nnewly burnished. Defaced and repaired at different times, little was\\nleft of the original when the cross was cleared away in 1647, at the\\nsame time as Charing Cross.\\n\\nOnly three of the original Eleanor crosses remain: two in\\nNorthamptonshire--one at Geddington, and the other at Northampton, and\\nthe third at Waltham Cross. Every Englishman should be proud of these\\nglorious records of a past age, which not only tell of the devoted love\\nof two sovereigns, of whom we all must be proud, but also because they\\nprove the high state of English art at this time. Until late years, when\\ncertain documents were discovered containing the names of the artists,\\nthe historians of art attempted to believe that the designs were too\\ngood for Englishmen, and must have been made by foreigners.\\n\\nIn order to establish peace between England and France, King Edward\\nmarried Margaret of France, siste\", 'pile_set_name': 'Gutenberg (PG-19)'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"len(ds1): {len(ds1)}\")\n",
    "print(f\"ds1[0]: {ds1[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-mm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
